	\subsection[Fundamentals about signal processing]{Fundamentals about signal processsing\footnote{For a more complete introduction to the domain, please see appendix \ref{norem}} }
	\subsubsection{Definition of a signal}
	Lopez's PhD \cite{lopez} gives a good presentation of the state of the art.
	Many notations and definitions are kept from this PhD.

	Note that a bold symbol (for example $\boldsymbol{h}$) denotes a matrix, that may be a vector.
	On the contrary, a normal symbol (for example $\varepsilon_{t_1}(k)$) denotes a single value

	\begin{thdef}\label{sig} (Signal)
		Generally, a signal is a temporal variable, which takes a value from $\mathbb{R}$ at each time t.
		$x(t)$ denotes the value of the signal $x$ at the instant $t$.
		When dealing with discrete time events, the time will be represented by $k$.
		The notation will then be $x(k)$, which is said to be a sample.
		$\{x(k)\}_{k \geq 0}$ denotes all the values possible for the signal x.
		The rest of this report adresses vectors of signals $\textbf{x}$, where $\textbf{x}(k) \in \mathbb{R}^{n}$
	\end{thdef}

	%\subsubsection{$l^\infty$ norm}
	%\begin{thdef}\label{l_inf} ($\ell^\infty$ norm)
	%	The $\ell^\infty$ norm of a scalar signal x, denoted $\|x\|_{\ell^\infty}$, is the smallest upper bound among all values (absolute values) possible for the signal x, that is:
	%	\begin{equation} \label{l3}
	%			\|x\|_{\ell^\infty}=\sup_{k\in \mathbb{N}}|x(k)|
	%	\end{equation}
	%\end{thdef}

	\subsubsection[Linear Time Invariant Filters (LTI Filters)]{Linear Time Invariant Filters (LTI filters)\footnote{For more information about the studied filters, please refer to appendix \ref{fildef}}}
	A filter, denoted by its transfer function $\mathcal{H}$, is an application which transforms a signal vector $\boldsymbol{u}$ (with $dim(\boldsymbol{u}) = n_u$ )
	into a signal vector $\boldsymbol{y} = \mathcal{H}(\boldsymbol{u})$, of size $dim(\boldsymbol{y}) = n_y$ . The case where $n_u = n_y = 1$ is referred as Single Input Single Output
	(SISO) filters. Other cases are referred as Multiple Input Multiple Output (MIMO) filters.

	\begin{thdef} (Linear Time Invariant Filter)

		Linearity:
		$$ \mathcal{H}(\alpha \cdot \boldsymbol{u}_1+ \beta \cdot \boldsymbol{u}_2)= \alpha\cdot\mathcal{H}(\boldsymbol{u}_1) +  \beta\cdot\mathcal{H}(\boldsymbol{u}_2)$$

		Time invariance:
		$$ \{\mathcal{H}(\boldsymbol{u})(k-k_0)\}_{k\geq0} = \mathcal{H}(\{\boldsymbol{u}(k-k_0)\}_{k \geq 0} ) $$
	\end{thdef}

	%\subsubsection{Impulse response}
	%\begin{thdef} (Impulse Response)
	%A SISO filter may be defined by its impulse response, denoted $h$. $h$ is the
	%impulse response of H to the impulsion of Dirac.
	%Indeed each input signal can be described as a sum of Dirac impulsions:
	%$$u=\sum_{i\geq0}u(l)\delta_l$$
	%where $\delta_l$ is a Dirac impulsion centered in $l$, that is:
	%\begin{equation}
	%	\delta_l(k) =
	%	\begin{cases}
	%		1 & \hspace{5pt} when \hspace{5pt} k=l\\
	%		0 & \hspace{5pt} else\\
	%	\end{cases}
	%\end{equation}
	%The linearity condition of $\mathcal{H}$ implies: $\mathcal{H}(u) = \sum_{l\geq0}u(l)\mathcal{H}(\delta_l)$.
	%Time invariance gives: $\mathcal{H}(\delta_l)(k)=h(k-l)$.
	%Then the computation from inputs to outputs takes this form:
	%$$y(k)=\sum_{l\geq0}u(l)h(k-l)=\sum_{l=0}^ku(k)h(k-l)$$
	%This corresponds with the convolution product definition of $u$ by $h$, denoted $y = h * u$.
	%%Dealing with MIMO filters, we have $\boldsymbol{h} \in \mathbb{R}^{n_y \times n_u}$ as the impulse response of $\mathcal{H}$. $\boldsymbol{h}_{i,j}$ is the response on the
	%Dealing with MIMO filters, $\boldsymbol{h}(k) \in \mathbb{R}^{n_y \times n_u}$ is the impulse response of $\mathcal{H}$. $\boldsymbol{h}_{i,j}(k)$ is the response on the
	%ith output to the Dirac implusion on the j-th input.
	%The precedent equation becomes:
	%$$y_i(k)=\sum_{j=1}^{n_u}\sum_{l=0}^ku_j(l)h_{i,j}(k-l), \hspace{5pt} \forall 1 \leq i \leq n_y$$
	%
	%\end{thdef} 

	\subsubsection{Worst-Case Peak Gain (WCPG) of a Filter: the maximum possible amplification}
	\begin{thdef} (Worst-Case Peak Gain)
		The worst case peak gain is defined as the maximum amplification
		possible over all potential inputs through the filter.
		$$\|\mathcal{H}\|_{wcpg}=\sup_{u\neq0}\frac{\|h*u\|_{l^{\infty}}}{\|u\|_{l^{\infty}}}$$
		with $h$ the impulse response of $\mathcal{H}$, $u$ the input signal, and $h * u$ the convolution product of $h$ by $u$ (output of the
				filter).
	
	\end{thdef}
%	\subsection{FIR and IIR: two filters families}
%	There are two types of LTI filters: \textit{Finite impulse response} (FIR) and \textit{Infinite impulse response} (IIR) filters.
%	Formally, the impulse response is finite when:
%	\begin{equation} \label{finimp}
%		\exists n \in \mathbb{N} | \forall k \geq n, h(k)=0
%	\end{equation}
%	The smallest $n$ verifying \ref{finimp} is referred as the order of the filter. So a $n$-order FIR can be described by the
%	following equation:
%	\begin{equation} \label{firdef}
%		y(k)=\sum_{i=0}^n b_i u(k-i)
%	\end{equation}
%
%	An IIR will be described as following:
%	\begin{equation} \label{iirdef}
%		y(k)=\sum_{i=0}^n b_i u(k-i) - \sum_{i=0}^n a_i y(k-i)
%	\end{equation}
%
%	%Here one can observe that the output at time $k$ depends also on all previous $n$ outputs (loopback). 
%	%Also remark that a FIR can be seen as an IIR with $\forall i \in [0,n],a_i=0$
%	%The impulse response can then be deduced from \ref{iirdef} by resolving the recurrence relation:
%
%	%\begin{equation}
%	%	h(k) =
%	%	\begin{cases}
%	%		0 & when \hspace{5pt} k<l\\
%	%		b_k - \sum_{l=1}^n a_l h(k-l) & when \hspace{5pt} 0\leq k \leq n\\
%	%		\sum_{l=1}^n a_l h(k-l) & when \hspace{5pt} n< k\\
%	%	\end{cases}
%	%\end{equation}

	\subsection{Different realizations: how to compute the output of a filter?}
	\begin{thdef} (realization)
	A realization can be defined as an algorithm describing how to compute outputs
	from inputs. However, a realization does not describes the details of basic operations (format, size,
	rounding, etc...)
	\end{thdef}
	It is important to know that all realizations of a filter are mathematically equivalent to each other (infinite
	precision). But in finite precision, rounding aspects have a huge impact on the correctness of results.
	Most of the time in this report, realizations will be referred as forms.

%	\subsubsection{Direct and transposed forms}
%	Direct and transposed forms are classic realizations. A good description of these forms can be found in Lopez’ and Hilaire’s PhDs \cite{lopez} \cite{hilaire}. 
%	The direct form has been implemented in the FoPoCo project,
%	The hardware implementation of anIIR can be seen on figure \ref{fig:ltiarch}
%
%\begin{figure*}[h]
%  \centering
%  \begin{tikzpicture}
%     \draw[dotted,black, fill=yellow!20] (-5ex,-3.5ex) rectangle +(69ex,-15ex);   
%     \node[black]  at (-2ex,-17.5ex) {{\small SOPC}};   
%    \draw[hwbus] (-8, 0) node[left] {$u(k)$} --  ++(8, 0)  ;
%    \draw[hwbus,->] (-8, 0) --  ++(3, 0); % just for the arrow
%    \foreach \i in {0,...,3} {
%      \draw[hwbus, ->] ($(8*\i, 0)$) --  ++(0, -5);
%      \draw[hwblock] ($(8*\i, -5)$) -- ++(3, 0) -- ++(-3, -4) -- ++(-3, 4) -- cycle; 
%      \node (n) at ($(8*\i , -6.5)$)  {$b_{\i}$} ;
%%      \draw ($(8*\i  + 0.5, -11)$) node[left,tt=black!50] {\footnotesize $p_b(k,\i)$} ;
%%      \draw ($(8*\i  - 0.2, -11)$) node[right,text=black!50] {\footnotesize $p_b(k,\i)$} ;
%
%%      \draw[hwbus, ->] ($(8*\i ex, 0ex)$) --  ++(0, -5ex);
%    }
%
%    
%    \draw[hwbus] (0, -9) -- ++(0,-6);
%      \coordinate (n) at  (0,-15);
%    \foreach \i in {1,...,3} {
%      \draw[line width=3pt] ($(8*\i  - 4, -3)$) --  +(0, 6);
%      \draw[hwbus] ($(8*\i  - 8, 0)$) --  +(8,0) node [above,text=blue] {\footnotesize $u(k-\i)$};
%      \draw[hwbus,->] ($(8*\i  - 8, 0)$) --  ++(3, 0); % just for the arrow
%      % The adders 
%      \coordinate (nm1) at  (n.east);
%      \draw ($(8*\i , -15)$) node[hwblock,circle,minimum height=3] (n) {$+$};
%      \draw[hwbus, ->]  ($(8*\i , -9)$) -- (n.north);
%      \draw[hwbus, ->]  (nm1) -- (n.west);
%      \draw[hwbus]  (n.east) -- ++ (3,0);
%    }
%
%    \draw (74, -15) node[hwblock,align=center] (fr) {final\\round} ;
%    \draw[hwbus, <-] (fr.west) -- ++(-15,0) node [near end] {/} node [near end,below] {\footnotesize$(\msbout, p-g$)} node[near start,above] {$\appr{y}(k)$} -- ++(-1,0) ;
%    \draw[hwbus, ->] (fr.east) -- ++(8,0) node [midway] {/} node [midway,below] {\footnotesize$(\msbout,p)$} node[right] {$\yout(k)$} ;
%
%    \foreach \i in {1,...,3} {
%      \draw[hwbus, ->] ($(-8*\i  + 60 , 0)$) --  ++(0, -5);
%      \draw[hwblock] ($(-8*\i  + 60 , -5)$) -- ++(3, 0) -- ++(-3, -4) -- ++(-3, 4) -- cycle; 
%      \node (ai) at ($(-8*\i  + 60 , -6.5)$)  {$a_{\i}$} ;
%      %\draw ($(-8*\i  +60 + 0.5, -11)$) node[left,text=black!50] {\footnotesize $p_a(k,\i)$} ;
%      %\draw ($(-8*\i  +60 - 0.2, -11)$) node[right,text=black!50] {\footnotesize $p_a(k,\i)$} ;
%      \draw ($(-8*\i  + 60 , -15)$) node[hwblock,circle,minimum height=3] (n) {$+$};
%      \draw (n.north) node[left]{\bf -};
%      \draw[hwbus, ->] ($(-8*\i  + 60, -9)$) --  (n.north);
%      \draw[hwbus, <-] (n.west) -- ++(-5,0);
%      % The registers
%      \draw[hwbus] ($(-8*\i  + 60  +8, 0)$) --  ++(-8, 0) node [above,text=blue] {\footnotesize $\appr{y}(k-\i)$};
%      \draw[hwbus,->] ($(-8*\i  + 60  +8, 0)$) --  ++(-3, 0); % just for the arrow
%      \draw[line width=3pt] ($(-8*\i  +60 + 4, -3)$) --  +(0, 6);
%    }
%    \draw[hwbus] ($(60 , 0)$) --  ++(0,-15);
%    \draw[hwbus,<-] ($(60 , -5)$) --  ++(0,-5);
%
%
%  \end{tikzpicture}
%
%\caption{Abstract architecture for the direct form realization of an LTI filter \label{fig:ltiarch}}
%\end{figure*}
%
%	\subsubsection{State-space representation: a recurrence to define an infinite response}
	%This type of realization consists in expressing the evolution of a system considering its state at time $k$. In
	\vspace{10pt}
	The state-space representation is a type of realization consists in expressing the evolution of a system considering its state at time $k$. In
	continuous time, it is described by differential equations at first order. In discret time (in which we
	are interested in), it is described by a simple recurrence:
	\begin{equation} \label{abcddef}
		\begin{cases}
			\boldsymbol{x}(k+1)= \boldsymbol{Ax}(k) + \boldsymbol{Bu}(k) \\
			\boldsymbol{y}(k+1)= \boldsymbol{Cx}(k) + \boldsymbol{Du}(k)
		\end{cases}
	\end{equation}

	Where $\boldsymbol{x}(k) \in \mathbb{R}^{n_x}$ is the state vector,
	$\boldsymbol{u}(k) \in \mathbb{R}^{n_u}$ is the input vector and
	$\boldsymbol{y}(k) \in \mathbb{R}^{n_y}$ is the output vector, at time k.
	The matrices $\boldsymbol{A} \in \mathbb{R}^{n_x \times n_x}$ , $\boldsymbol{B} \in \mathbb{R}^{n_x \times n_u}$,
	$\boldsymbol{C} \in \mathbb{R}^{n_y \times n_x}$, and $\boldsymbol{D} \in \mathbb{R}^{n_y \times n_u}$,
	with $\boldsymbol{x}(0)$ are sufficient to describe an LTI filter, with convention $\boldsymbol{x}(k)=\boldsymbol{u}(k)=0 \hspace{5pt}, \hspace{5pt} \forall k<0$.

	\subsection{The Specialized Implicit Form (SIF): a unified representation}
	\subsubsection{Definition}
	The classical state-space representation is intuitive, but it doesn't take into account the reality of implementation.
	The specialized implicit form (SIF) was introduced in \cite{sifd}, is well detailed in Hilaire's PhD and associated papers \cite{hilaire,sif},
	and is a good answer to this problem.
	Indeed, dealing with finite precision and error amplification, the order in which operations are done becomes crucial.
	Another motivation is to have a unique representation for any realization of LTI filters,
	that allows to compute every degradation measures instead of redevelopping them for each new realization.
	This form distinguishes computations done at one time from computations done the other times. As well as
	in a state-space, $\boldsymbol{x}$-coordinates are state variables, but in addition to that, $\boldsymbol{t}$-coordinates are intermediate variables.
	The SIF is described as following:
	\begin{equation} \label{sifdef}
		\begin{pmatrix}
			\boldsymbol{J} & \boldsymbol{0} & \boldsymbol{0} \\
			\boldsymbol{-K} & \boldsymbol{I}_{n_x} & \boldsymbol{0} \\
			\boldsymbol{-L} & \boldsymbol{0} & \boldsymbol{I}_{n_y} 
		\end{pmatrix}
		\begin{pmatrix}
			\boldsymbol{t} (k+1)  \\
			\boldsymbol{x} (k+1)  \\
			\boldsymbol{y} (k) 
		\end{pmatrix}
		=
		\begin{pmatrix}
			\boldsymbol{0} & \boldsymbol{M} & \boldsymbol{N} \\
			\boldsymbol{0} & \boldsymbol{P} & \boldsymbol{Q} \\
			\boldsymbol{0} & \boldsymbol{R} & \boldsymbol{S} 
		\end{pmatrix}
		\begin{pmatrix}
			\boldsymbol{t} (k)  \\
			\boldsymbol{x} (k)  \\
			\boldsymbol{u} (k) 
		\end{pmatrix}
	\end{equation}
%	With $n_t$, $n_x$, $n_y$ and $n_u$ the sizes of $\boldsymbol{t}$, $\boldsymbol{x}$, $\boldsymbol{y}$ and $\boldsymbol{u}$, respectively.
%	$\boldsymbol{J}$, is a lower triangular matrix, with
%	diagonal entries equal to 1.
%	%Then we have the following dimensions for the previous matrices:
%	The previous matrices have the following dimensions:
%
%	\begin{eqnarray}
%		\boldsymbol{J} \in \mathbb{R}^{n_t \times n_t},\boldsymbol{M} \in \mathbb{R}^{n_t \times n_x},\boldsymbol{N} \in \mathbb{R}^{n_t \times n_u}, \nonumber \\
%		\boldsymbol{K} \in \mathbb{R}^{n_x \times n_t},\boldsymbol{P} \in \mathbb{R}^{n_x \times n_x},\boldsymbol{Q} \in \mathbb{R}^{n_x \times n_u}, \\
%		\boldsymbol{L} \in \mathbb{R}^{n_y \times n_t},\boldsymbol{R} \in \mathbb{R}^{n_y \times n_x},\boldsymbol{S} \in \mathbb{R}^{n_y \times n_u}, \nonumber \\
%	\end{eqnarray}

	The best way to understand the SIF may be to see it as an algorithm, each line of the equation \ref{sifdef} corresponding to a sequential step of the computation.
	%The algorithm results as follows:
	%\begin{algorithm}
	%	\For{int i = 0 ; $i \leq n_t$; i++}{
	%		$\boldsymbol{t}_i(k+1) \leftarrow - \sum\limits\limits_{j<i} \boldsymbol{J}_{ij}\boldsymbol{t}_j(k+1) + \sum\limits_{j=1}^{n_x} \boldsymbol{M}_{ij}\boldsymbol{x}_j(k) + \sum\limits_{j=1}^{n_u} \boldsymbol{N}_{ij}\boldsymbol{u}_j(k)$
	%	}
	%	\For{int i = 0 ; $i \leq n_x$; i++}{
	%		$\boldsymbol{x}_i(k+1) \leftarrow - \sum\limits_{j=1}^{n_t} \boldsymbol{K}_{ij}\boldsymbol{t}_j(k+1) + \sum\limits_{j=1}^{n_x} \boldsymbol{P}_{ij}\boldsymbol{x}_j(k) + \sum\limits_{j=1}^{n_u} \boldsymbol{Q}_{ij}\boldsymbol{u}_j(k)$
	%	}
	%	\For{int i = 0 ; $i \leq ny$; i++}{
	%		$\boldsymbol{y}_i(k) \leftarrow - \sum\limits_{j=1}^{n_t} \boldsymbol{L}_{ij}\boldsymbol{t}_j(k+1) + \sum\limits_{j=1}^{n_x} \boldsymbol{R}_{ij}\boldsymbol{x}_j(k) + \sum\limits_{j=1}^{n_u} \boldsymbol{S}_{ij}\boldsymbol{u}_j(k)$
	%	}
	%	\caption{Computation of SIF outputs from inputs}
	%\end{algorithm}

	%Here, it is important to see that the form of $\boldsymbol{J}$ allows to compute the $\boldsymbol{t}_i$ sequentially. The algorithm can
	%then be described as follows:
	%\begin{algorithm} \label{algomat}
	%	\For{int i = 0 ; $i \leq n_t$; i++}{
	%		$\boldsymbol{t}_i(k+1) \leftarrow - \boldsymbol{J'}_{i}\boldsymbol{t}(k+1) + \boldsymbol{M}_{i}\boldsymbol{x}(k) +\boldsymbol{N}_{i}\boldsymbol{u}(k)$
	%	}
	%	\For{int i = 0 ; $i \leq n_x$; i++}{
	%		$\boldsymbol{x}_i(k+1) \leftarrow - \boldsymbol{K}_{i}\boldsymbol{t}(k+1) + \boldsymbol{P}_{i}\boldsymbol{x}(k) +\boldsymbol{Q}_{i}\boldsymbol{u}(k)$
	%	}
	%	\For{int i = 0 ; $i \leq ny$; i++}{
	%		$\boldsymbol{y}_i(k) \leftarrow - \boldsymbol{L}_{i}\boldsymbol{t}(k+1) + \boldsymbol{R}_{i}\boldsymbol{x}(k) + \boldsymbol{S}_{i}\boldsymbol{u}(k)$
	%	}
	%	\caption{Simplified matricial algorithm}
	%\end{algorithm}

	%With $\boldsymbol{J'} = \boldsymbol{J} - I_{n_t}$.

	Values of the vector $\boldsymbol{t}(k+1)$ are computed and used at the same iterations, so they are not kept in memory.
	As the equation \ref{sifdef} is mostly full of zeros, it is more convenient to use it’s compressed formulation, which is denoted
	$\boldsymbol{Z}$:
	
	\begin{equation} \label{zmatrix}
		\boldsymbol{Z}=
		\begin{pmatrix}
			\boldsymbol{-J} & \boldsymbol{M} & \boldsymbol{N} \\
			\boldsymbol{K} & \boldsymbol{P} & \boldsymbol{Q} \\
			\boldsymbol{L} & \boldsymbol{R} & \boldsymbol{S} 
		\end{pmatrix}
	\end{equation}

	The community usually takes $-\boldsymbol{J}$ for simplicity within further computations.

	%The SIF can of course be transformed into an equivalent ABCD (classic state-space) form, which gives:
	The SIF can of course be transformed into an equivalent ABCD (classic state-space) form.
	About parallelism, it is useful to remark that $t(k+1)$ are computed sequentially, while $x(k+1)$ and $y(k)$ can be computed in parallel.
%
%	\begin{eqnarray} \label{abcdtranspose}
%		\boldsymbol{A_Z} = \boldsymbol{KJ}^{-1}\boldsymbol{M} +\boldsymbol{P}, \hspace{5pt}
%		\boldsymbol{B_Z} = \boldsymbol{KJ}^{-1}\boldsymbol{N} +\boldsymbol{Q}, \nonumber \\
%		\boldsymbol{C_Z} = \boldsymbol{LJ}^{-1}\boldsymbol{M} +\boldsymbol{R}, \hspace{5pt}
%		\boldsymbol{D_Z} = \boldsymbol{LJ}^{-1}\boldsymbol{N} +\boldsymbol{S}, \nonumber \\
%	\end{eqnarray}
%
%	with:
%	\begin{eqnarray}
%		\boldsymbol{A_Z} \in \mathbb{R}^{n_x \times n_x},
%		\boldsymbol{B_Z} \in \mathbb{R}^{n_x \times n_u}, \nonumber \\
%		\boldsymbol{C_Z} \in \mathbb{R}^{n_y \times n_x},
%		\boldsymbol{D_Z} \in \mathbb{R}^{n_y \times n_u},
%	\end{eqnarray}

	\subsubsection{Workflow for filter implementation}
		%Here, we won't discuss the optimality of the SIF description.
		The choice of the SIF realization is not concerned by this work.
		This choice is up to the user, who may have a lot of good reasons not to design a realization that seem intuitive for us.
		The choice of the realization is a job done at LIP6 in the PEQUAN team, under the metalibm ANR project.
		The present work is just a hardware backend for the choice part.
		Of course, optimizations are available at every level.
		The expected use of this work is shown on figure \ref{fig:workflow}.


		\begin{figure}[h] 
		  \centering
		  \begin{tikzpicture}[x=0.8cm,y=1cm]
			\draw (-9.5, 1.0) -- (-8,1.0) [->, thick] node[above,near start, text width = 3cm, align=center]{User filter specification};
			\draw (-3.5, 1.0) -- (0.0,1.0) [->, thick] node[below,xshift=-1.4cm]{$\begin{pmatrix}\boldsymbol{-J} & \boldsymbol{M} & \boldsymbol{M}_t \\ \boldsymbol{K} & \boldsymbol{P} & \boldsymbol{M}_x \\ \boldsymbol{L} & \boldsymbol{R} & \boldsymbol{M}_y \end{pmatrix}$};
			\draw (-8,-0.3) rectangle ++(4.5,2.4)[thick] node [midway, text width = 4cm, align=center]{Realization Choice \\ by \\ Hilaire, Volkova  \\ team PEQUAN, LIP6 \\(Front-End)}; 
			\draw (0.0,0.0) rectangle ++(3.0,2)[thick] node [midway, text width = 3cm, align=center]{Flopoco core generation \\ (this work) \\(Back-End)}; 

			\draw (4,0) rectangle ++(2.5,2)[thick] node [midway]{VHDL}; 
			\draw (3.0, 1) -- (4,1) [->, thick] node[above,near start]{};

		  \end{tikzpicture}

		\caption{Workflow overview of tools usage \label{fig:workflow}}
		\end{figure}










%	\subsection{Adjustments in arbitrary precision}

	





%		
%	\subsection{Canonical specification}
%		
%		The intuitive and first way to describe an LTI filter is to specify the output as a function of the inputs:
%		$$y(k)=\sum_{i=0}^n b_i u(k-i)-\sum_{i=1}^n a_i y(k-i)$$
%
%	\subsection{Z transform}
%	$$X(z)=\mathcal{Z}\{x\}=\sum_{k=0}^{+\infty} x(k) z^{-k}$$
%	
%	\subsection{Transfert Function}
%	A filter is usually described by it's transfert function, defined as:
%
%	$$H(z)=\frac{Y(z)}{U(z)}=\frac{\sum_{i=0}^n b_i z^{-i}}{ 1 + \sum_{i=1}^n a_i z^{-i}}, \;\;\;\; \forall z \in \mathbb{C}$$ 
%	\subsection{Impulse response}
%	$\delta$
%	\subsection{Worst case peak gain (WCPG)}
%	$$\| \mathcal{H} \|_{WCPG}=\sup_{i\neq 0} \frac{\|h*u\|_{l^\infty}}{\|u\|_{l^\infty}} $$
%
%	$$\| \mathcal{H} \|_{WCPG}= \sum_{k \geq 0} |h(k)| $$
%	\subsection{Realisations}



	



